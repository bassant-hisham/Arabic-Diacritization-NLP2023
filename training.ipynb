{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Team Members</h2>\n",
    "<ul>\n",
    "<li>Sohad Hossam Eldin 1190019</li>\n",
    "<li>Bassant Hisham Mohamed 1190018</li>\n",
    "<li>Yasmin Hashem Niazy 4200013</li>\n",
    "<li>Mary Ashraf 1190322</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pyarabic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install diacritization-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Imports</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from pyarabic.araby import strip_tashkeel\n",
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "from diacritization_evaluation import util\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Reading the dataset</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "dataset_txt = open(r\"train.txt\", \"r\", encoding='utf-8').read()\n",
    "print(type(dataset_txt))\n",
    "#print(dataset_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cleaning the dataset</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we need to remove [ :ص]\n",
    "chars_to_remove = r\"\\(\\s*[a-zA-Z0-9_-]+\\s*/\\s*[a-zA-Z0-9_-]+\\s*\\)|[a-zA-Z0-9_-]+\" \n",
    "dataset_cleaned = re.sub(chars_to_remove, \"\", dataset_txt)\n",
    "#print(dataset_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Segmenting dataset into sentences</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['قَوْلُهُ', '', 'أَوْ قَطَعَ الْأَوَّلُ يَدَهُ إلَخْ', 'قَالَ الزَّرْكَشِيُّ', 'ابْنُ عَرَفَةَ', 'قَوْلُهُ', 'بِلَفْظٍ يَقْتَضِيه كَإِنْكَارِ غَيْرِ حَدِيثٍ بِالْإِسْلَامِ وُجُوبَ مَا عُلِمَ وُجُوبُهُ مِنْ الدِّينِ ضَرُورَةً', 'كَإِلْقَاءِ مُصْحَفٍ بِقَذَرٍ وَشَدِّ زُنَّارٍ', 'ابْنُ عَرَفَةَ', 'قَوْلُ ابْنِ شَاسٍ', 'أَوْ بِفِعْلٍ يَتَضَمَّنُهُ هُوَ كَلُبْسِ الزُّنَّارِ وَإِلْقَاءِ الْمُصْحَفِ فِي صَرِيحِ النَّجَاسَةِ وَالسُّجُودِ لِلصَّنَمِ وَنَحْوِ ذَلِكَ', 'وَسِحْرٍ', 'مُحَمَّدٌ', 'قَوْلُ مَالِكٍ وَأَصْحَابِهِ أَنَّ السَّاحِرَ كَافِرٌ بِاَللَّهِ تَعَالَى قَالَ مَالِكٌ', 'هُوَ كَالزِّنْدِيقِ إذَا عَمِلَ السِّحْرَ بِنَفْسِهِ قُتِلَ وَلَمْ يُسْتَتَبْ', '', 'قَوْلُهُ لِعَدَمِ مَا تَتَعَلَّقُ إلَخْ', 'أَيْ الْوَصِيَّةُ', 'قَوْلُهُ مَا مَرَّ', 'أَيْ قُبَيْلَ قَوْلِ الْمَتْنِ لَغَتْ وَلَوْ اقْتَصَرَ عَلَى أَوْصَيْت لَهُ بِشَاةٍ أَوْ أَعْطُوهُ شَاةً وَلَا غَنَمَ لَهُ عِنْدَ الْمَوْتِ هَلْ تَبْطُلُ الْوَصِيَّةُ أَوْ يُشْتَرَى لَهُ شَاةٌ وَيُؤْخَذُ مِنْ قَوْلِهِ الْآتِي كَمَا لَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي أَنَّهَا لَا تَبْطُلُ', 'وَعِبَارَةُ الْكَنْزِ وَلَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي لَمْ يَتَعَيَّنْ غَنَمُهُ إنْ كَانَتْ انْتَهَتْ ا ه سم', 'قَوْلُهُ فَيُعْطَى وَاحِدَةً مِنْهَا إلَخْ', 'كَمَا لَوْ كَانَتْ مَوْجُودَةً عِنْدَ الْوَصِيَّةِ وَالْمَوْتِ', 'وَلَا يَجُوزُ أَنْ يُعْطَى وَاحِدَةً مِنْ غَيْرِ غَنَمِهِ فِي الصُّورَتَيْنِ وَإِنْ تَرَاضَيَا', 'لِأَنَّهُ صُلْحٌ عَلَى مَجْهُولٍ مُغْنِي وَنِهَايَةٌ قَالَ ع ش قَوْلُهُ وَاحِدَةً مِنْهَا أَيْ كَامِلَةً', 'وَلَا يَجُوزُ أَنْ يُعْطَى نِصْفَيْنِ مِنْ شَاتَيْنِ', 'لِأَنَّهُ لَا يُسَمَّى شَاةً وَقَوْلُهُ وَلَا يَجُوزُ أَنْ يُعْطَى وَاحِدَةً مِنْ غَيْرِ غَنَمِهِ وَيَنْبَغِي أَنْ يُقَالَ مِثْلُ ذَلِكَ فِي الْأَرِقَّاءِ ا ه', 'وَحَيَوَانٌ غَيْرُ مَوْجُودٍ', 'فَائِدَةٌ', 'قَالَ بَعْضُهُمْ']\n"
     ]
    }
   ],
   "source": [
    "# r'(\\([^)]*\\))' should we remove the brackets or not\n",
    "dataset_sentences = re.split(r\"\\s*\\.\\s*|\\n|\\s*،\\s*|\\s*:\\s*|\\s*[()]\\s*|\\s*؛\\s*|\\s*؟\\s*|\\s*!\\s*|\\s*\\\"\\s*\",dataset_cleaned)\n",
    "print(type(dataset_sentences))\n",
    "print(dataset_sentences[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Removing Tashkeel</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_without_tashkeel = strip_tashkeel(dataset_cleaned)\n",
    "##print(dataset_without_tashkeel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Tokenizing the sentence</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train_letters = []\n",
    "y_train_letters = []\n",
    "x_train_words = []\n",
    "y_train_words = []\n",
    "for sentence in dataset_sentences:\n",
    "    sentence_wihout_diacratics = strip_tashkeel(sentence)\n",
    "    tokens = word_tokenize(sentence, language=\"arabic\", preserve_line=True)\n",
    "    tokens_wihtout_diacratics = word_tokenize(sentence_wihout_diacratics, language=\"arabic\", preserve_line=True)\n",
    "   \n",
    "    for word in tokens:\n",
    "        text, inputs, diacritics =util.extract_haraqat(word)\n",
    "        x_train_letters.append(inputs)\n",
    "        y_train_letters.append(diacritics)\n",
    "\n",
    "    if(len(tokens)) :\n",
    "        tokens.insert(0, \"<s>\")\n",
    "        tokens.append(\"</s>\")\n",
    "        y_train_words.append(tokens)\n",
    "    if(len(tokens_wihtout_diacratics)) :\n",
    "        tokens_wihtout_diacratics.insert(0, \"<s>\")\n",
    "        tokens_wihtout_diacratics.append(\"</s>\")\n",
    "        x_train_words.append(tokens_wihtout_diacratics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizing the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ق', 'و', 'ل', 'ه'], ['أ', 'و'], ['ق', 'ط', 'ع'], ['ا', 'ل', 'أ', 'و', 'ل'], ['ي', 'د', 'ه'], ['إ', 'ل', 'خ'], ['ق', 'ا', 'ل'], ['ا', 'ل', 'ز', 'ر', 'ك', 'ش', 'ي'], ['ا', 'ب', 'ن'], ['ع', 'ر', 'ف', 'ة']]\n",
      "[['َ', 'ْ', 'ُ', 'ُ'], ['َ', 'ْ'], ['َ', 'َ', 'َ'], ['', 'ْ', 'َ', 'َّ', 'ُ'], ['َ', 'َ', 'ُ'], ['', 'َ', 'ْ'], ['َ', '', 'َ'], ['', '', 'َّ', 'ْ', 'َ', 'ِ', 'ُّ'], ['', 'ْ', 'ُ'], ['َ', 'َ', 'َ', 'َ']]\n",
      "[['<s>', 'قَوْلُهُ', '</s>'], ['<s>', 'أَوْ', 'قَطَعَ', 'الْأَوَّلُ', 'يَدَهُ', 'إلَخْ', '</s>'], ['<s>', 'قَالَ', 'الزَّرْكَشِيُّ', '</s>'], ['<s>', 'ابْنُ', 'عَرَفَةَ', '</s>'], ['<s>', 'قَوْلُهُ', '</s>'], ['<s>', 'بِلَفْظٍ', 'يَقْتَضِيه', 'كَإِنْكَارِ', 'غَيْرِ', 'حَدِيثٍ', 'بِالْإِسْلَامِ', 'وُجُوبَ', 'مَا', 'عُلِمَ', 'وُجُوبُهُ', 'مِنْ', 'الدِّينِ', 'ضَرُورَةً', '</s>'], ['<s>', 'كَإِلْقَاءِ', 'مُصْحَفٍ', 'بِقَذَرٍ', 'وَشَدِّ', 'زُنَّارٍ', '</s>'], ['<s>', 'ابْنُ', 'عَرَفَةَ', '</s>'], ['<s>', 'قَوْلُ', 'ابْنِ', 'شَاسٍ', '</s>'], ['<s>', 'أَوْ', 'بِفِعْلٍ', 'يَتَضَمَّنُهُ', 'هُوَ', 'كَلُبْسِ', 'الزُّنَّارِ', 'وَإِلْقَاءِ', 'الْمُصْحَفِ', 'فِي', 'صَرِيحِ', 'النَّجَاسَةِ', 'وَالسُّجُودِ', 'لِلصَّنَمِ', 'وَنَحْوِ', 'ذَلِكَ', '</s>']]\n",
      "[['<s>', 'قوله', '</s>'], ['<s>', 'أو', 'قطع', 'الأول', 'يده', 'إلخ', '</s>'], ['<s>', 'قال', 'الزركشي', '</s>'], ['<s>', 'ابن', 'عرفة', '</s>'], ['<s>', 'قوله', '</s>'], ['<s>', 'بلفظ', 'يقتضيه', 'كإنكار', 'غير', 'حديث', 'بالإسلام', 'وجوب', 'ما', 'علم', 'وجوبه', 'من', 'الدين', 'ضرورة', '</s>'], ['<s>', 'كإلقاء', 'مصحف', 'بقذر', 'وشد', 'زنار', '</s>'], ['<s>', 'ابن', 'عرفة', '</s>'], ['<s>', 'قول', 'ابن', 'شاس', '</s>'], ['<s>', 'أو', 'بفعل', 'يتضمنه', 'هو', 'كلبس', 'الزنار', 'وإلقاء', 'المصحف', 'في', 'صريح', 'النجاسة', 'والسجود', 'للصنم', 'ونحو', 'ذلك', '</s>']]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_letters[0:10])\n",
    "print(y_train_letters[0:10])\n",
    "print(y_train_words[0:10])\n",
    "print(x_train_words[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['ق', 'ط', 'ع']\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train_letters))\n",
    "print(x_train_letters[2])\n",
    "\n",
    "#ouh lala , tokinze is dividing the tashkelat as indpendent letters as well , what does that tell us tho "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
