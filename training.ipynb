{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Team Members</h2>\n",
    "<ul>\n",
    "<li>Sohad Hossam Eldin 1190019</li>\n",
    "<li>Bassant Hisham Mohamed 1190018</li>\n",
    "<li>Yasmin Hashem Niazy 4200013</li>\n",
    "<li>Mary Ashraf 1190322</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarabic in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.6.15)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyarabic) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tkseem in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.0.3)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tkseem) (0.1.99)\n",
      "Requirement already satisfied: farasapy in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tkseem) (0.0.14)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tkseem) (4.66.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tkseem) (1.26.2)\n",
      "Requirement already satisfied: black in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tkseem) (23.11.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from black->tkseem) (8.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from black->tkseem) (1.0.0)\n",
      "Requirement already satisfied: packaging>=22.0 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from black->tkseem) (23.2)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from black->tkseem) (0.11.2)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from black->tkseem) (4.1.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from black->tkseem) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from black->tkseem) (4.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from farasapy->tkseem) (2.31.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm->tkseem) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->farasapy->tkseem) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->farasapy->tkseem) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->farasapy->tkseem) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->farasapy->tkseem) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "%pip install pyarabic \n",
    "%pip install tkseem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (23.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diacritization-evaluation in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install diacritization-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Imports</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from pyarabic.araby import strip_tashkeel\n",
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "import tkseem \n",
    "from diacritization_evaluation import util\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Reading the dataset</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "dataset_txt = open(r\"train.txt\", \"r\", encoding='utf-8').read()\n",
    "print(type(dataset_txt))\n",
    "#print(dataset_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cleaning the dataset</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we need to remove [ :ص]\n",
    "chars_to_remove = r\"\\(\\s*[a-zA-Z0-9_-]+\\s*/\\s*[a-zA-Z0-9_-]+\\s*\\)|[a-zA-Z0-9_-]+\" \n",
    "dataset_cleaned = re.sub(chars_to_remove, \"\", dataset_txt)\n",
    "#print(dataset_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Segmenting dataset into sentences</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['قَوْلُهُ', '', 'أَوْ قَطَعَ الْأَوَّلُ يَدَهُ إلَخْ', 'قَالَ الزَّرْكَشِيُّ', 'ابْنُ عَرَفَةَ', 'قَوْلُهُ', 'بِلَفْظٍ يَقْتَضِيه كَإِنْكَارِ غَيْرِ حَدِيثٍ بِالْإِسْلَامِ وُجُوبَ مَا عُلِمَ وُجُوبُهُ مِنْ الدِّينِ ضَرُورَةً', 'كَإِلْقَاءِ مُصْحَفٍ بِقَذَرٍ وَشَدِّ زُنَّارٍ', 'ابْنُ عَرَفَةَ', 'قَوْلُ ابْنِ شَاسٍ', 'أَوْ بِفِعْلٍ يَتَضَمَّنُهُ هُوَ كَلُبْسِ الزُّنَّارِ وَإِلْقَاءِ الْمُصْحَفِ فِي صَرِيحِ النَّجَاسَةِ وَالسُّجُودِ لِلصَّنَمِ وَنَحْوِ ذَلِكَ', 'وَسِحْرٍ', 'مُحَمَّدٌ', 'قَوْلُ مَالِكٍ وَأَصْحَابِهِ أَنَّ السَّاحِرَ كَافِرٌ بِاَللَّهِ تَعَالَى قَالَ مَالِكٌ', 'هُوَ كَالزِّنْدِيقِ إذَا عَمِلَ السِّحْرَ بِنَفْسِهِ قُتِلَ وَلَمْ يُسْتَتَبْ', '', 'قَوْلُهُ لِعَدَمِ مَا تَتَعَلَّقُ إلَخْ', 'أَيْ الْوَصِيَّةُ', 'قَوْلُهُ مَا مَرَّ', 'أَيْ قُبَيْلَ قَوْلِ الْمَتْنِ لَغَتْ وَلَوْ اقْتَصَرَ عَلَى أَوْصَيْت لَهُ بِشَاةٍ أَوْ أَعْطُوهُ شَاةً وَلَا غَنَمَ لَهُ عِنْدَ الْمَوْتِ هَلْ تَبْطُلُ الْوَصِيَّةُ أَوْ يُشْتَرَى لَهُ شَاةٌ وَيُؤْخَذُ مِنْ قَوْلِهِ الْآتِي كَمَا لَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي أَنَّهَا لَا تَبْطُلُ', 'وَعِبَارَةُ الْكَنْزِ وَلَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي لَمْ يَتَعَيَّنْ غَنَمُهُ إنْ كَانَتْ انْتَهَتْ ا ه سم', 'قَوْلُهُ فَيُعْطَى وَاحِدَةً مِنْهَا إلَخْ', 'كَمَا لَوْ كَانَتْ مَوْجُودَةً عِنْدَ الْوَصِيَّةِ وَالْمَوْتِ', 'وَلَا يَجُوزُ أَنْ يُعْطَى وَاحِدَةً مِنْ غَيْرِ غَنَمِهِ فِي الصُّورَتَيْنِ وَإِنْ تَرَاضَيَا', 'لِأَنَّهُ صُلْحٌ عَلَى مَجْهُولٍ مُغْنِي وَنِهَايَةٌ قَالَ ع ش قَوْلُهُ وَاحِدَةً مِنْهَا أَيْ كَامِلَةً', 'وَلَا يَجُوزُ أَنْ يُعْطَى نِصْفَيْنِ مِنْ شَاتَيْنِ', 'لِأَنَّهُ لَا يُسَمَّى شَاةً وَقَوْلُهُ وَلَا يَجُوزُ أَنْ يُعْطَى وَاحِدَةً مِنْ غَيْرِ غَنَمِهِ وَيَنْبَغِي أَنْ يُقَالَ مِثْلُ ذَلِكَ فِي الْأَرِقَّاءِ ا ه', 'وَحَيَوَانٌ غَيْرُ مَوْجُودٍ', 'فَائِدَةٌ', 'قَالَ بَعْضُهُمْ']\n"
     ]
    }
   ],
   "source": [
    "# r'(\\([^)]*\\))' should we remove the brackets or not\n",
    "dataset_sentences = re.split(r\"\\s*\\.\\s*|\\n|\\s*،\\s*|\\s*:\\s*|\\s*[()]\\s*|\\s*؛\\s*|\\s*؟\\s*|\\s*!\\s*|\\s*\\\"\\s*\",dataset_cleaned)\n",
    "print(type(dataset_sentences))\n",
    "print(dataset_sentences[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Removing Tashkeel</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_without_tashkeel = strip_tashkeel(dataset_cleaned)\n",
    "##print(dataset_without_tashkeel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Tokenizing the sentence</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = []\n",
    "for sentence in dataset_sentences:\n",
    "    tokens = word_tokenize(sentence, language=\"arabic\", preserve_line=True)\n",
    "    if(len(tokens)) :\n",
    "        tokens.insert(0, \"<s>\")\n",
    "        tokens.append(\"</s>\")\n",
    "        tokenized_sentences.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[['<s>', 'قَوْلُهُ', '</s>'], ['<s>', 'أَوْ', 'قَطَعَ', 'الْأَوَّلُ', 'يَدَهُ', 'إلَخْ', '</s>'], ['<s>', 'قَالَ', 'الزَّرْكَشِيُّ', '</s>'], ['<s>', 'ابْنُ', 'عَرَفَةَ', '</s>'], ['<s>', 'قَوْلُهُ', '</s>'], ['<s>', 'بِلَفْظٍ', 'يَقْتَضِيه', 'كَإِنْكَارِ', 'غَيْرِ', 'حَدِيثٍ', 'بِالْإِسْلَامِ', 'وُجُوبَ', 'مَا', 'عُلِمَ', 'وُجُوبُهُ', 'مِنْ', 'الدِّينِ', 'ضَرُورَةً', '</s>'], ['<s>', 'كَإِلْقَاءِ', 'مُصْحَفٍ', 'بِقَذَرٍ', 'وَشَدِّ', 'زُنَّارٍ', '</s>'], ['<s>', 'ابْنُ', 'عَرَفَةَ', '</s>'], ['<s>', 'قَوْلُ', 'ابْنِ', 'شَاسٍ', '</s>'], ['<s>', 'أَوْ', 'بِفِعْلٍ', 'يَتَضَمَّنُهُ', 'هُوَ', 'كَلُبْسِ', 'الزُّنَّارِ', 'وَإِلْقَاءِ', 'الْمُصْحَفِ', 'فِي', 'صَرِيحِ', 'النَّجَاسَةِ', 'وَالسُّجُودِ', 'لِلصَّنَمِ', 'وَنَحْوِ', 'ذَلِكَ', '</s>']]\n",
      "قَوْلُهُ\n",
      "['ق', 'و', 'ل', 'ه']\n",
      "['َ', 'ْ', 'ُ', 'ُ']\n"
     ]
    }
   ],
   "source": [
    "print(type(tokenized_sentences))\n",
    "print(tokenized_sentences[0:10])\n",
    "#print(tokenized_sentences[1][1])\n",
    "yasmin ='الْأَوَّلُ'\n",
    "text, inputs, diacritics = util.extract_haraqat(tokenized_sentences[0][1])\n",
    "print(text)\n",
    "print(inputs)\n",
    "print(diacritics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizing the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m sentence_without_s\u001b[38;5;241m=\u001b[39msentence[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      6\u001b[0m x_train_letters\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<s>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43my_train_letters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence_without_s:\n\u001b[0;32m      9\u001b[0m     text, inputs, diacritics \u001b[38;5;241m=\u001b[39mutil\u001b[38;5;241m.\u001b[39mextract_haraqat(word)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train_letters = []\n",
    "y_train_letters = []\n",
    "for sentence in tokenized_sentences:\n",
    "    sentence_without_s=sentence[1:-1]\n",
    "\n",
    "    x_train_letters.insert(0, \"<s>\")\n",
    "    y_train_letters.insert(0, \"\")\n",
    "    for word in sentence_without_s:\n",
    "        text, inputs, diacritics =util.extract_haraqat(word)\n",
    "        x_train_letters.append(inputs)\n",
    "        y_train_letters.append(diacritics)\n",
    "\n",
    "    \n",
    "    x_train_letters.append(\"</s>\")\n",
    "    y_train_letters.append(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['<s>', 'أ', 'َ', 'و', 'ْ', 'ق', 'َ', 'ط', 'َ', 'ع', 'َ', 'ا', 'ل', 'ْ', 'أ', 'َ', 'و', 'ّ', 'َ', 'ل', 'ُ', 'ي', 'َ', 'د', 'َ', 'ه', 'ُ', 'إ', 'ل', 'َ', 'خ', 'ْ', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train_letters))\n",
    "print(x_train_letters[2])\n",
    "\n",
    "#ouh lala , tokinze is dividing the tashkelat as indpendent letters as well , what does that tell us tho "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
